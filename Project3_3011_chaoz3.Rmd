---
title: "Project3_3011_chaoz3"
author: "zhuchao"
date: "29/11/2020"
output: html_document
---

```{r}
library('text2vec')
library('glmnet')
library('pROC')
set.seed(3011)
```
I used the procedures described in Piazza post "what have we tried I".

Read the entire datasets of all reviews. Remove punctuations from the reviews.
```{r}

train = read.table("alldata.tsv",
                   stringsAsFactors = FALSE,
                   header = TRUE)
train$review = gsub('<.*?>', ' ', train$review)
```

Create the document term matrix. The procedures are: 1)convert all characters to lower case; 2)tokenize each words; 3)remove stop words from the stop_words list; 4) take the terms based on 1/2/3/4 grams 5)remove terms based on criteria: number of occurences over all documents is lower than 10 (potential rare words), proportion of documents containing the term greater than 0.5 (potential high-frequent words but not delivering extra meanings), proportion of documents containing ther term less than 0.001 (potential rare words)
```{r}
stop_words = c("i", "me", "my", "myself", 
               "we", "our", "ours", "ourselves", 
               "you", "your", "yours", 
               "their", "they", "his", "her", 
               "she", "he", "a", "an", "and",
               "is", "was", "are", "were", 
               "him", "himself", "has", "have", 
               "it", "its", "the", "us")
it_train = itoken(train$review,
                  preprocessor = tolower, 
                  tokenizer = word_tokenizer)
tmp.vocab = create_vocabulary(it_train, 
                              stopwords = stop_words, 
                              ngram = c(1L,4L))
tmp.vocab = prune_vocabulary(tmp.vocab, term_count_min = 10,
                             doc_proportion_max = 0.5,
                             doc_proportion_min = 0.001)
dtm_train  = create_dtm(it_train, vocab_vectorizer(tmp.vocab))
```

Use a lasso regression to fit a model to classify the sentiment of each document. Lasso regression will force the coefficient of some terms to be 0, meaning those terms are not important for sentiment classification. 
I chose the maximum number of terms below 2k, which is 1933 in my case below

```{r}
tmpfit = glmnet(x = dtm_train, 
                y = train$sentiment, 
                alpha = 1,
                family='binomial')
tmpfit$df
```

```{r}
myvocab = colnames(dtm_train)[which(tmpfit$beta[, 41] != 0)]
write.table(myvocab, file = 'myvocab.txt', sep = '\n',row.names = FALSE, col.names = FALSE)
```



```{r}

j = 1
setwd(paste("split_", j, sep="")) 
train = read.table("train.tsv",
                           stringsAsFactors = FALSE,
                           header = TRUE)
train$review <- gsub('<.*?>', ' ', train$review)
it_train = itoken(train$review,
                            preprocessor = tolower, 
                            tokenizer = word_tokenizer)
vectorizer = vocab_vectorizer(create_vocabulary(myvocab, 
                                                          ngram = c(1L, 2L)))
dtm_train = create_dtm(it_train, vectorizer)
        
mylogit.cv = cv.glmnet(x = dtm_train, 
                                 y = train$sentiment, 
                                 alpha = 0.6,
                                 family='binomial', 
                                 type.measure = "auc")
mylogit.fit = glmnet(x = dtm_train, 
                               y = train$sentiment, 
                               alpha = 0.6,
                               lambda = mylogit.cv$lambda.min, 
                               family='binomial')
        
test = read.table("test.tsv",
                            stringsAsFactors = FALSE,
                            header = TRUE)
test$review <- gsub('<.*?>', ' ', test$review)
it_test = itoken(test$review,
                           preprocessor = tolower, 
                           tokenizer = word_tokenizer)
dtm_test = create_dtm(it_test, vectorizer)
mypred = predict(mylogit.fit, dtm_test, type = "response")
output = data.frame(id = test$id, prob = as.vector(mypred))
write.table(output, file = "mysubmission.txt", 
                    row.names = FALSE, sep='\t')
          
test.y = read.table("test_y.tsv", header = TRUE)
pred = read.table("mysubmission.txt", header = TRUE)
pred = merge(pred, test.y, by="id")
roc_obj = roc(pred$sentiment, pred$prob)
tmp = pROC::auc(roc_obj)
print(tmp)

```

```{r}
j = 2
setwd(paste("split_", j, sep="")) 
train = read.table("train.tsv",
                           stringsAsFactors = FALSE,
                           header = TRUE)
train$review <- gsub('<.*?>', ' ', train$review)
it_train = itoken(train$review,
                            preprocessor = tolower, 
                            tokenizer = word_tokenizer)
vectorizer = vocab_vectorizer(create_vocabulary(myvocab, 
                                                          ngram = c(1L, 2L)))
dtm_train = create_dtm(it_train, vectorizer)
        
mylogit.cv = cv.glmnet(x = dtm_train, 
                                 y = train$sentiment, 
                                 alpha = 0.6,
                                 family='binomial', 
                                 type.measure = "auc")
mylogit.fit = glmnet(x = dtm_train, 
                               y = train$sentiment, 
                               alpha = 0.6,
                               lambda = mylogit.cv$lambda.min, 
                               family='binomial')
        
test = read.table("test.tsv",
                            stringsAsFactors = FALSE,
                            header = TRUE)
test$review <- gsub('<.*?>', ' ', test$review)
it_test = itoken(test$review,
                           preprocessor = tolower, 
                           tokenizer = word_tokenizer)
dtm_test = create_dtm(it_test, vectorizer)
mypred = predict(mylogit.fit, dtm_test, type = "response")
output = data.frame(id = test$id, prob = as.vector(mypred))
write.table(output, file = "mysubmission.txt", 
                    row.names = FALSE, sep='\t')
          
test.y = read.table("test_y.tsv", header = TRUE)
pred = read.table("mysubmission.txt", header = TRUE)
pred = merge(pred, test.y, by="id")
roc_obj = roc(pred$sentiment, pred$prob)
tmp = pROC::auc(roc_obj)
print(tmp)
```


```{r}
j = 3
setwd(paste("split_", j, sep="")) 
train = read.table("train.tsv",
                           stringsAsFactors = FALSE,
                           header = TRUE)
train$review <- gsub('<.*?>', ' ', train$review)
it_train = itoken(train$review,
                            preprocessor = tolower, 
                            tokenizer = word_tokenizer)
vectorizer = vocab_vectorizer(create_vocabulary(myvocab, 
                                                          ngram = c(1L, 2L)))
dtm_train = create_dtm(it_train, vectorizer)
        
mylogit.cv = cv.glmnet(x = dtm_train, 
                                 y = train$sentiment, 
                                 alpha = 0.6,
                                 family='binomial', 
                                 type.measure = "auc")
mylogit.fit = glmnet(x = dtm_train, 
                               y = train$sentiment, 
                               alpha = 0.6,
                               lambda = mylogit.cv$lambda.min, 
                               family='binomial')
        
test = read.table("test.tsv",
                            stringsAsFactors = FALSE,
                            header = TRUE)
test$review <- gsub('<.*?>', ' ', test$review)
it_test = itoken(test$review,
                           preprocessor = tolower, 
                           tokenizer = word_tokenizer)
dtm_test = create_dtm(it_test, vectorizer)
mypred = predict(mylogit.fit, dtm_test, type = "response")
output = data.frame(id = test$id, prob = as.vector(mypred))
write.table(output, file = "mysubmission.txt", 
                    row.names = FALSE, sep='\t')
          
test.y = read.table("test_y.tsv", header = TRUE)
pred = read.table("mysubmission.txt", header = TRUE)
pred = merge(pred, test.y, by="id")
roc_obj = roc(pred$sentiment, pred$prob)
tmp = pROC::auc(roc_obj)
print(tmp)
```


```{r}
j = 4
setwd(paste("split_", j, sep="")) 
train = read.table("train.tsv",
                           stringsAsFactors = FALSE,
                           header = TRUE)
train$review <- gsub('<.*?>', ' ', train$review)
it_train = itoken(train$review,
                            preprocessor = tolower, 
                            tokenizer = word_tokenizer)
vectorizer = vocab_vectorizer(create_vocabulary(myvocab, 
                                                          ngram = c(1L, 2L)))
dtm_train = create_dtm(it_train, vectorizer)
        
mylogit.cv = cv.glmnet(x = dtm_train, 
                                 y = train$sentiment, 
                                 alpha = 0.6,
                                 family='binomial', 
                                 type.measure = "auc")
mylogit.fit = glmnet(x = dtm_train, 
                               y = train$sentiment, 
                               alpha = 0.6,
                               lambda = mylogit.cv$lambda.min, 
                               family='binomial')
        
test = read.table("test.tsv",
                            stringsAsFactors = FALSE,
                            header = TRUE)
test$review <- gsub('<.*?>', ' ', test$review)
it_test = itoken(test$review,
                           preprocessor = tolower, 
                           tokenizer = word_tokenizer)
dtm_test = create_dtm(it_test, vectorizer)
mypred = predict(mylogit.fit, dtm_test, type = "response")
output = data.frame(id = test$id, prob = as.vector(mypred))
write.table(output, file = "mysubmission.txt", 
                    row.names = FALSE, sep='\t')
          
test.y = read.table("test_y.tsv", header = TRUE)
pred = read.table("mysubmission.txt", header = TRUE)
pred = merge(pred, test.y, by="id")
roc_obj = roc(pred$sentiment, pred$prob)
tmp = pROC::auc(roc_obj)
print(tmp)
```

```{r}
j = 5
setwd(paste("split_", j, sep="")) 
train = read.table("train.tsv",
                           stringsAsFactors = FALSE,
                           header = TRUE)
train$review <- gsub('<.*?>', ' ', train$review)
it_train = itoken(train$review,
                            preprocessor = tolower, 
                            tokenizer = word_tokenizer)
vectorizer = vocab_vectorizer(create_vocabulary(myvocab, 
                                                          ngram = c(1L, 2L)))
dtm_train = create_dtm(it_train, vectorizer)
        
mylogit.cv = cv.glmnet(x = dtm_train, 
                                 y = train$sentiment, 
                                 alpha = 0.6,
                                 family='binomial', 
                                 type.measure = "auc")
mylogit.fit = glmnet(x = dtm_train, 
                               y = train$sentiment, 
                               alpha = 0.6,
                               lambda = mylogit.cv$lambda.min, 
                               family='binomial')
        
test = read.table("test.tsv",
                            stringsAsFactors = FALSE,
                            header = TRUE)
test$review <- gsub('<.*?>', ' ', test$review)
it_test = itoken(test$review,
                           preprocessor = tolower, 
                           tokenizer = word_tokenizer)
dtm_test = create_dtm(it_test, vectorizer)
mypred = predict(mylogit.fit, dtm_test, type = "response")
output = data.frame(id = test$id, prob = as.vector(mypred))
write.table(output, file = "mysubmission.txt", 
                    row.names = FALSE, sep='\t')
          
test.y = read.table("test_y.tsv", header = TRUE)
pred = read.table("mysubmission.txt", header = TRUE)
pred = merge(pred, test.y, by="id")
roc_obj = roc(pred$sentiment, pred$prob)
tmp = pROC::auc(roc_obj)
print(tmp)
```





